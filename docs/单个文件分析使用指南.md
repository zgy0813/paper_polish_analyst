# å•ä¸ªPDFæ–‡ä»¶åˆ†æä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨è®ºæ–‡é£æ ¼åˆ†æä¸æ¶¦è‰²ç³»ç»Ÿè¿›è¡Œå•ä¸ªPDFæ–‡ä»¶åˆ†æã€‚ä¸æ‰¹é‡åˆ†æä¸åŒï¼Œå•ä¸ªæ–‡ä»¶åˆ†æä¸“æ³¨äºé€ä¸€å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶ï¼Œæä¾›æ›´ç²¾ç»†çš„æ§åˆ¶å’Œç›‘æ§ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

### âœ… ä¸»è¦ç‰¹æ€§
- **ç‹¬ç«‹åˆ†æ**ï¼šä¸ä¾èµ–æ‰¹é‡åˆ†æï¼Œå¯ä»¥å•ç‹¬è¿è¡Œ
- **è¿›åº¦è·Ÿè¸ª**ï¼šå®æ—¶ç›‘æ§åˆ†æè¿›åº¦å’ŒçŠ¶æ€
- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­åˆ†æ
- **çµæ´»æ§åˆ¶**ï¼šå¯ä»¥é™åˆ¶åˆ†ææ–‡ä»¶æ•°é‡
- **é”™è¯¯å¤„ç†**ï¼šè¯¦ç»†çš„é”™è¯¯æ—¥å¿—å’Œå¤±è´¥æ–‡ä»¶è®°å½•
- **ç»Ÿè®¡åˆ†æ**ï¼šæä¾›å®Œæ•´çš„åˆ†æç»Ÿè®¡ä¿¡æ¯

### ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹
- **åˆ†å±‚æ¸©åº¦é…ç½®**ï¼šä¸åŒä»»åŠ¡ä½¿ç”¨æœ€é€‚åˆçš„AIå‚æ•°
- **å¥å£®JSONè§£æ**ï¼šå¤šå±‚çº§è§£æç­–ç•¥ç¡®ä¿æˆåŠŸ
- **æ™ºèƒ½è¿‡æ»¤**ï¼šè‡ªåŠ¨è·³è¿‡å·²åˆ†æçš„æ–‡ä»¶
- **è¯¦ç»†æ—¥å¿—**ï¼šè®°å½•æ‰€æœ‰åˆ†æè¿‡ç¨‹å’Œé”™è¯¯

## ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œä½¿ç”¨

#### åŸºæœ¬ç”¨æ³•
```bash
# åˆ†ææ‰€æœ‰PDFæ–‡ä»¶
python main.py analyze-individual

# é™åˆ¶åˆ†ææ•°é‡
python main.py analyze-individual --max-papers 10

# ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­
python main.py analyze-individual --resume

# æ˜¾ç¤ºå®æ—¶è¿›åº¦
python main.py analyze-individual --progress
```

#### å‚æ•°è¯´æ˜
- `--max-papers, -m`: æœ€å¤§åˆ†æè®ºæ–‡æ•°é‡ï¼Œä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰
- `--resume`: ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­åˆ†æ
- `--progress`: æ˜¾ç¤ºå®æ—¶åˆ†æè¿›åº¦

### 2. ç¼–ç¨‹æ¥å£ä½¿ç”¨

#### åŸºæœ¬ç¤ºä¾‹
```python
from src.analysis.layered_analyzer import LayeredAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = LayeredAnalyzer()

# åˆ†ææ‰€æœ‰æ–‡ä»¶
result = analyzer.analyze_all_individual_papers()

# æ£€æŸ¥ç»“æœ
if 'error' in result:
    print(f"åˆ†æå¤±è´¥: {result['error']}")
else:
    print(f"åˆ†æå®Œæˆ: {result['successful_papers']}/{result['total_papers']}")
```

#### é«˜çº§ç”¨æ³•
```python
# é™åˆ¶åˆ†ææ•°é‡
result = analyzer.analyze_all_individual_papers(max_papers=5)

# ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­
result = analyzer.analyze_all_individual_papers(resume=True)

# è·å–åˆ†æè¿›åº¦
progress = analyzer.get_analysis_progress()
print(f"è¿›åº¦: {progress['completed_files']}/{progress['total_files']}")
```

## åˆ†ææµç¨‹

### 1. æ–‡ä»¶å‘ç°
- æ‰«æ `data/extracted/` ç›®å½•ä¸­çš„æ‰€æœ‰ `.txt` æ–‡ä»¶
- æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿åˆ†æé¡ºåºä¸€è‡´

### 2. æ–‡ä»¶è¿‡æ»¤
- æ£€æŸ¥ `data/individual_reports/` ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨åˆ†ææŠ¥å‘Š
- è·³è¿‡å·²æˆåŠŸåˆ†æçš„æ–‡ä»¶
- é‡æ–°åˆ†ææœ‰é”™è¯¯çš„æ–‡ä»¶

### 3. é€ä¸ªåˆ†æ
- ä½¿ç”¨NLPå·¥å…·è¿›è¡ŒåŸºç¡€åˆ†æ
- è°ƒç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ
- ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶

### 4. è¿›åº¦è·Ÿè¸ª
- å®æ—¶æ›´æ–°åˆ†æè¿›åº¦
- è®°å½•æˆåŠŸå’Œå¤±è´¥çš„æ–‡ä»¶æ•°é‡
- æä¾›å½“å‰æ­£åœ¨åˆ†æçš„æ–‡ä»¶ä¿¡æ¯

### 5. ç»“æœæ±‡æ€»
- ç”Ÿæˆè¯¦ç»†çš„åˆ†ææ‘˜è¦
- ç»Ÿè®¡æ–‡æœ¬é•¿åº¦å’Œè¯æ•°ä¿¡æ¯
- è®°å½•å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨

## è¾“å‡ºæ–‡ä»¶

### 1. ä¸ªä½“åˆ†ææŠ¥å‘Š
ä½ç½®ï¼š`data/individual_reports/{paper_id}.json`

```json
{
  "paper_id": "example_paper",
  "analysis_date": "2025-01-14T10:30:00",
  "nlp_analysis": {
    "sentence_structure": {...},
    "vocabulary": {...},
    "paragraph_structure": {...},
    "academic_expression": {...}
  },
  "gpt_analysis": {
    "writing_patterns": {...},
    "style_characteristics": {...}
  },
  "text_length": 50000,
  "word_count": 8000
}
```

### 2. åˆ†ææ‘˜è¦
ä½ç½®ï¼š`data/individual_analysis_summary.json`

```json
{
  "analysis_type": "individual_only",
  "analysis_date": "2025-01-14T10:30:00",
  "total_papers": 82,
  "successful_papers": 80,
  "failed_papers": 2,
  "success_rate": 0.975,
  "text_statistics": {
    "avg_text_length": 45000,
    "min_text_length": 20000,
    "max_text_length": 80000,
    "avg_word_count": 7200,
    "min_word_count": 3200,
    "max_word_count": 12800
  },
  "failed_papers": ["paper1", "paper2"],
  "progress": {
    "total_files": 82,
    "completed_files": 80,
    "failed_files": 2,
    "current_file": null
  }
}
```

### 3. é”™è¯¯æ—¥å¿—
ä½ç½®ï¼š`logs/json_parse_errors.json`

```json
{
  "timestamp": "2025-01-14T10:30:00",
  "task_type": "individual_analysis",
  "error": "JSONè§£æé”™è¯¯è¯¦æƒ…",
  "response_length": 1500,
  "response_preview": "å“åº”å†…å®¹é¢„è§ˆ..."
}
```

## é…ç½®å‚æ•°

### 1. æ¸©åº¦é…ç½®
```python
temperature_config = {
    'individual_analysis': 0.4,    # å•ç¯‡åˆ†æéœ€è¦åˆ›é€ æ€§
    'batch_summary': 0.3,          # æ‰¹æ¬¡æ±‡æ€»éœ€è¦å¹³è¡¡
    'global_integration': 0.2,     # å…¨å±€æ•´åˆéœ€è¦ç¨³å®š
    # ... å…¶ä»–ä»»åŠ¡ç±»å‹
}
```

### 2. Tokené…ç½®
```python
max_tokens_config = {
    'individual_analysis': 15000,    # å•ç¯‡åˆ†æ
    'batch_summary': 20000,          # æ‰¹æ¬¡æ±‡æ€»
    'global_integration': 25000,     # å…¨å±€æ•´åˆ
    # ... å…¶ä»–ä»»åŠ¡ç±»å‹
}
```

## ç›‘æ§å’Œè°ƒè¯•

### 1. å®æ—¶è¿›åº¦ç›‘æ§
```python
import time

analyzer = LayeredAnalyzer()

# å¯åŠ¨åˆ†æï¼ˆåœ¨åå°çº¿ç¨‹ä¸­ï¼‰
import threading
analysis_thread = threading.Thread(
    target=analyzer.analyze_all_individual_papers
)
analysis_thread.start()

# ç›‘æ§è¿›åº¦
while analysis_thread.is_alive():
    progress = analyzer.get_analysis_progress()
    print(f"è¿›åº¦: {progress['completed_files']}/{progress['total_files']}")
    time.sleep(5)
```

### 2. é”™è¯¯è°ƒè¯•
```python
# æ£€æŸ¥å¤±è´¥çš„æ–‡ä»¶
result = analyzer.analyze_all_individual_papers()
if result['failed_papers']:
    print("å¤±è´¥çš„æ–‡ä»¶:")
    for paper_id in result['failed_papers']:
        print(f"  - {paper_id}")
        
        # æ£€æŸ¥å…·ä½“çš„é”™è¯¯ä¿¡æ¯
        report_file = f"data/individual_reports/{paper_id}.json"
        with open(report_file, 'r') as f:
            report = json.load(f)
            if 'error' in report:
                print(f"    é”™è¯¯: {report['error']}")
```

### 3. æ—¥å¿—åˆ†æ
```bash
# æŸ¥çœ‹åˆ†ææ—¥å¿—
tail -f logs/app_*.log

# æŸ¥çœ‹JSONè§£æé”™è¯¯
cat logs/json_parse_errors.json | jq '.'
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤§å°è°ƒæ•´
- å¯¹äºå¤§é‡æ–‡ä»¶ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†
- æ¯æ‰¹å¤„ç†10-20ä¸ªæ–‡ä»¶ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜

### 2. é”™è¯¯å¤„ç†
- å®šæœŸæ£€æŸ¥é”™è¯¯æ—¥å¿—
- åŠæ—¶å¤„ç†è§£æå¤±è´¥çš„æ–‡ä»¶
- ä½¿ç”¨resumeåŠŸèƒ½é¿å…é‡å¤åˆ†æ

### 3. èµ„æºç›‘æ§
- ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ
- æ³¨æ„APIè°ƒç”¨é¢‘ç‡é™åˆ¶
- å®šæœŸæ¸…ç†ä¸´æ—¶æ–‡ä»¶

## å¸¸è§é—®é¢˜

### Q1: åˆ†æè¿‡ç¨‹ä¸­æ–­æ€ä¹ˆåŠï¼Ÿ
A: ä½¿ç”¨ `--resume` å‚æ•°ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­åˆ†æã€‚

### Q2: å¦‚ä½•åªåˆ†æç‰¹å®šçš„æ–‡ä»¶ï¼Ÿ
A: ç›®å‰ä¸æ”¯æŒç›´æ¥æŒ‡å®šæ–‡ä»¶ï¼Œä½†å¯ä»¥é€šè¿‡ä¿®æ”¹ `data/extracted/` ç›®å½•ä¸­çš„æ–‡ä»¶æ¥æ§åˆ¶ã€‚

### Q3: åˆ†æé€Ÿåº¦å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
A: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®ï¼Œè€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹æˆ–è°ƒæ•´å‚æ•°ã€‚

### Q4: å¦‚ä½•æŸ¥çœ‹åˆ†æè¿›åº¦ï¼Ÿ
A: ä½¿ç”¨ `--progress` å‚æ•°æˆ–ç¼–ç¨‹æ¥å£çš„ `get_analysis_progress()` æ–¹æ³•ã€‚

### Q5: åˆ†æç»“æœåœ¨å“ªé‡Œï¼Ÿ
A: ä¸ªä½“åˆ†æç»“æœåœ¨ `data/individual_reports/` ç›®å½•ï¼Œæ‘˜è¦åœ¨ `data/individual_analysis_summary.json`ã€‚

## æœ€ä½³å®è·µ

1. **å®šæœŸå¤‡ä»½**ï¼šåˆ†æå‰å¤‡ä»½é‡è¦æ•°æ®
2. **åˆ†æ‰¹å¤„ç†**ï¼šå¤§é‡æ–‡ä»¶æ—¶åˆ†æ‰¹åˆ†æ
3. **ç›‘æ§è¿›åº¦**ï¼šä½¿ç”¨è¿›åº¦ç›‘æ§åŠŸèƒ½
4. **é”™è¯¯å¤„ç†**ï¼šåŠæ—¶å¤„ç†åˆ†æå¤±è´¥çš„æ–‡ä»¶
5. **æ—¥å¿—ç®¡ç†**ï¼šå®šæœŸæ¸…ç†å’Œå½’æ¡£æ—¥å¿—æ–‡ä»¶

## æ€»ç»“

å•ä¸ªPDFæ–‡ä»¶åˆ†æåŠŸèƒ½æä¾›äº†çµæ´»ã€å¯æ§çš„è®ºæ–‡åˆ†ææ–¹å¼ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦ç²¾ç»†æ§åˆ¶åˆ†æè¿‡ç¨‹çš„åœºæ™¯ã€‚é€šè¿‡åˆç†çš„é…ç½®å’Œä½¿ç”¨ï¼Œå¯ä»¥é«˜æ•ˆåœ°å®Œæˆå¤§é‡è®ºæ–‡çš„åˆ†æå·¥ä½œã€‚
